{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ENPM673_Project6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aJ3qJ6dpYwo3yyZJ6eIa1j7zxHh00rUX",
      "authorship_tag": "ABX9TyOE1bgvWG/EvCjERIuRd84X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrianBock/ENPM673-Project6/blob/master/ENPM673_Project6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbSoPuZcHrsH",
        "colab_type": "text"
      },
      "source": [
        "# ENPM 673 Project 6 - Image Classification via CNN\n",
        "Justin Albrecht & Brian Bock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAMV5NMD3NS8",
        "colab_type": "text"
      },
      "source": [
        "##Helpful Sources/References\n",
        "\n",
        "https://medium.com/@navneetkumar11/loading-image-data-from-google-drive-to-google-colab-using-pytorchs-dataloader-2e5617978a63\n",
        "\n",
        "https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c\n",
        "\n",
        "https://medium.com/dair-ai/pytorch-1-2-quickstart-with-google-colab-6690a30c38d\n",
        "\n",
        "https://colab.research.google.com/drive/1gCgtlnMPVWY0l1ra8ssS0EzJiWaVR4Pk#scrollTo=Su0COdCqT2Wk\n",
        "\n",
        "https://colab.research.google.com/drive/1Dr2kMGXjI_oi6x4Mke1PhPrWVe-3vQFm#scrollTo=AR6dYomrHZWr\n",
        "\n",
        "https://drive.google.com/file/d/1-aBdwzhJ3GXmqat1CBrjbdQF04Rj54Lj/view\n",
        "\n",
        "https://stackoverflow.com/questions/50052295/how-do-you-load-images-into-pytorch-dataloader\n",
        "\n",
        "https://towardsdatascience.com/a-beginners-tutorial-on-building-an-ai-image-classifier-using-pytorch-6f85cb69cba7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddoaggn0wiye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import required Python packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Import our own packages (if any)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqYV2w2KRYB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount drive (slow step, so we only want to do it once)\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTBp3Sni3xEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "82af41bc-c535-4eb0-e7cd-1419cbcdc58c"
      },
      "source": [
        "transformations = transforms.Compose([\n",
        "    transforms.Resize(255),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "image_path = (\"/content/drive/My Drive/2020/Spring 2020/ENPM673/Project 6/dogs-vs-cats/train\")\n",
        "train_set = datasets.ImageFolder(image_path, transform = transformations)\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUuH19Uu3f2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "d64f60a6-f84d-407e-af39-b5fc60eef696"
      },
      "source": [
        "# View images to verify import\n",
        "# helper function to un-normalize and display an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
        "\n",
        "    \n",
        "dataiter = iter(dataloaders)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "# display 20 images\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a2cea47ea6ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert images to numpy for display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# plot the images in the batch, along with the corresponding labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1ko4g3r4uBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in trainloader:\n",
        "    print(\"Image batch dimensions:\", images.shape)\n",
        "    print(\"Image label dimensions:\", labels.shape)\n",
        "    break\n",
        "\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        # 28x28x1 => 26x26x32\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
        "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
        "        self.d2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 32x1x28x28 => 32x32x26x26\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # flatten => 32 x (32*26*26)\n",
        "        x = x.flatten(start_dim = 1)\n",
        "\n",
        "        # 32 x (32*26*26) => 32x128\n",
        "        x = self.d1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # logits => 32x10\n",
        "        logits = self.d2(x)\n",
        "        out = F.softmax(logits, dim=1)\n",
        "        return out\n",
        "\n",
        "## test the model with 1 batch\n",
        "model = MyModel()\n",
        "for images, labels in trainloader:\n",
        "    print(\"batch size:\", images.shape)\n",
        "    out = model(images)\n",
        "    print(out.shape)\n",
        "    break\n",
        "\n",
        "# Train the Model\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MyModel()\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "## compute accuracy\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    model = model.train()\n",
        "\n",
        "    ## training step\n",
        "    for i, (images, labels) in enumerate(trainloader):\n",
        "        \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        ## forward + backprop + loss\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        ## update model params\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(logits, labels, BATCH_SIZE)\n",
        "    \n",
        "    model.eval()\n",
        "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
        "          %(epoch, train_running_loss / i, train_acc/i))    \n",
        "\n",
        "# Test the Model\n",
        "test_acc = 0.0\n",
        "for i, (images, labels) in enumerate(testloader, 0):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
        "        \n",
        "print('Test Accuracy: %.2f'%( test_acc/i))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}